---
title: "Why our food is so caloric?"
subtitle: "Bayesian Linear Regression of Food Nutrition"
author: "Thy Luong, Evgeniia Selezneva, Jasmine Wang"
format: beamer
---

# Introduction

## Statement of the Problem

-   How different nutrients affect the caloric value of food?

-   What nutrients have and don't have caloric value?

-   Do different types of food show different relationships between nutrients
and caloric value?


## Food Nutrition Dataset

\

-   2,395 rows (one row - one product)

-   5 groups of products

-   35 columns

-   32 different nutrients

-   food name, caloric value and nutrition density

\

\

Source: [Kaggle.com](https://www.kaggle.com/datasets/utsavdey1410/food-nutrition-dataset/data)

## EDA: Correlation Analysis

```{r corrplot, message=FALSE, echo=FALSE}
library(corrplot)
library(dplyr)
library(readr)
library(tidyverse)
library(monomvn)
library(BoomSpikeSlab)
library(car)
library(MASS)
library(knitr)


FOOD_DATA_GROUP1 <- read_csv("FINAL FOOD DATASET/FOOD-DATA-GROUP1.csv")
FOOD_DATA_GROUP2 <- read_csv("FINAL FOOD DATASET/FOOD-DATA-GROUP2.csv")
FOOD_DATA_GROUP3 <- read_csv("FINAL FOOD DATASET/FOOD-DATA-GROUP3.csv")
FOOD_DATA_GROUP4 <- read_csv("FINAL FOOD DATASET/FOOD-DATA-GROUP4.csv")
FOOD_DATA_GROUP5 <- read_csv("FINAL FOOD DATASET/FOOD-DATA-GROUP5.csv")

FOOD_DATA <- bind_rows(
  dplyr::mutate(FOOD_DATA_GROUP1, group = "group1"),
  dplyr::mutate(FOOD_DATA_GROUP2, group = "group2"),
  dplyr::mutate(FOOD_DATA_GROUP3, group = "group3"),
  dplyr::mutate(FOOD_DATA_GROUP4, group = "group4"),
  dplyr::mutate(FOOD_DATA_GROUP5, group = "group5")
) %>%
  # remove first two columns
  dplyr::select(-1, -2) %>%
  # replace spaces with underscores in colnames
  dplyr::rename_with(~ gsub(" ", "_", .x))


# Preprocess
df <- FOOD_DATA %>%
  dplyr::select(-food, -group, -Nutrition_Density) %>%
  drop_na()


M = cor(df[c("Caloric_Value", "Fat", "Saturated_Fats", "Monounsaturated_Fats",
             "Polyunsaturated_Fats", "Carbohydrates", "Sugars", "Protein")])
colnames(M) <- c("Caloric Value", "Fats", "Saturated Fats", "Monounsaturated Fats",
             "Polyunsaturated Fats", "Carbohydrates", "Sugars", "Protein")
rownames(M) <- colnames(M)
corrplot.mixed(M, diag="l", tl.pos = "lt", tl.col = "#000011", tl.srt = 45)
```

# Bayesian Analysis

## Bayesian Lasso Regression: Theory

$$\text{Regularization:}\quad \min_{\beta} \Big( \dfrac{1}{n} || Y - X \beta ||^2_2 + \lambda ||\beta||\Big)$$
<!-- $$\text{equivalent to: } \min_{\beta} \dfrac{1}{n} || Y - X \beta ||^2_2, \quad \text{s.t. }\,\, ||\beta|| \le \tau$$ -->

$$\mathbf{y} | \mu, \mathbf{X}, \boldsymbol{\beta}, \sigma^2 \sim N_n(\mu \mathbf{1}_n + \mathbf{X}\boldsymbol{\beta}, \sigma^2 \mathbf{I}_n)$$

$$\boldsymbol{\beta} | \sigma^2, \tau_1^2, \dots, \tau_p^2 \sim N_p(\mathbf{0}, \sigma^2 \mathbf{D}_{\tau})$$

$$\text{where}\quad \mathbf{D}_{\tau} = \text{diag}(\tau_1^2, \dots, \tau_p^2)$$

## Bayesian Lasso Regression: Results

Variables selected by Bayesian Lasso Model out of:

**All Regressors**:

-   *Fat*, Saturated Fats, Monounsaturated Fats, Polyunsaturated Fats, Carbohydrates, Protein, *Water*, Vitamin A, Magnesium, Phosphorus

**All Regressors without Fat**:

-   Saturated Fats, Monounsaturated Fats, Polyunsaturated Fats, Carbohydrates, Protein, *Cholesterol*, Vitamin A, *Vitamin E*, Magnesium, Phosphorus


```{r lasso, message=FALSE, echo=FALSE, include=FALSE, resilts="hide"}
y <- df$Caloric_Value
X <- df %>% dplyr::select(-Caloric_Value)

X_scaled <- scale(X)

set.seed(123)
bl_fit <- blasso(
  X = X_scaled,
  y = y,
  T = 10000,
  thin = 5,
  verb = 0
)

# Posterior mean of each coefficient
beta_mean <- apply(bl_fit$beta, 2, mean)
names(beta_mean) <- colnames(X_scaled)

# Rank nutrients by absolute effect size
ranked_lasso <- sort(abs(beta_mean), decreasing = TRUE)
head(ranked_lasso, 20)

beta_ci <- t(apply(bl_fit$beta, 2, quantile, probs = c(0.025, 0.975)))
colnames(beta_ci) <- c("low", "high")

# Selected nutrients from Bayesian Lasso
selected_lasso_ci <- rownames(beta_ci)[beta_ci[, "low"] > 0 | beta_ci[, "high"] < 0]
selected_lasso_ci # The Bayesian lasso thinks those predictors have credible, non-zero effects on "Caloric Value".

idx_sel <- as.integer(sub("b\\.", "", selected_lasso_ci))
idx_sel 

selected_nutrients <- colnames(X_scaled)[idx_sel]
selected_nutrients

X_without_fat <- X %>% dplyr::select(-Fat)

X_scaled_without_fat <- scale(X_without_fat)

# Bayesian Lasso without fat
set.seed(123)
bl_fit_without_fat <- blasso(
  X = X_scaled_without_fat,
  y = y,
  T = 10000,
  thin = 5,
  verb = 0
)

# Posterior mean of each coefficient
beta_mean_without_fat <- apply(bl_fit_without_fat$beta, 2, mean)
names(beta_mean_without_fat) <- colnames(X_scaled_without_fat)

# Rank nutrients by absolute effect size
ranked_lasso_without_fat <- sort(abs(beta_mean_without_fat), decreasing = TRUE)
head(ranked_lasso_without_fat, 20)

beta_ci_without_fat <- t(apply(bl_fit_without_fat$beta, 2, quantile, probs = c(0.025, 0.975)))
colnames(beta_ci_without_fat) <- c("low", "high")

# Selected nutrients from Bayesian Lasso
selected_lasso_ci_without_fat <- rownames(beta_ci_without_fat)[beta_ci_without_fat[, "low"] > 0 | beta_ci_without_fat[, "high"] < 0]
selected_lasso_ci_without_fat # The Bayesian lasso thinks those predictors have credible, non-zero effects on "Caloric Value".

idx_sel_without_fat <- as.integer(sub("b\\.", "", selected_lasso_ci_without_fat))
idx_sel_without_fat 

selected_nutrients_without_fat <- colnames(X_scaled_without_fat)[idx_sel_without_fat]
selected_nutrients_without_fat
```

## Spike-and-Slab Prior: Theory

\qquad $$\gamma_i \sim Bernoulli(\theta),$$
<!-- \qquad $$\beta_i\, |\, Z_i = 0 \sim \delta(\beta_i),$$ -->
<!-- \qquad $$\beta_i\, | \,Z_i = 1 \sim \mathcal{N}(0,\, \tau^{-1}),$$ -->
\qquad $$\beta_i\, |\, \gamma_i \sim (1 - \gamma_i)\, \mathcal{N}(0,\, \tau_o^{-1}) + \gamma_i\, \mathcal{N}(0,\, \tau_1^{-1}),$$
\qquad $$\text{ where } \tau_1 >> \tau_2 > 0,$$
\qquad $$\sigma^2 \sim \operatorname{Inv-Gamma}\Big(\dfrac{a_0}{2}, \dfrac{b_0}{2}\Big)$$
\qquad $$Y\, |\, \gamma,\, β,\, x ∼ \mathcal{N} \big( \langle \gamma \odot β, \,x\rangle, \,\sigma^2\big)$$


## Spike-and-Slab Prior: Results

Variables selected by Spike-and-Slab Prior method:

-   Magnesium, Vitamin A, Protein, Carbohydrates, Polyunsaturated Fats, Monounsaturated Fats, Saturated Fats, *Fat*, Phosphorus, *Water*, *Vitamin B6*, *Manganese*, *Calcium*

```{r spikeandslab, include=FALSE, results='hide', message=FALSE, echo=FALSE}
set.seed(123)
df_model <- data.frame(
  y = as.numeric(y),
  as.data.frame(X_scaled)
)

ss_fit <- lm.spike(
  y ~ .,
  data  = df_model,
  niter = 6000,                 
  expected.model.size = 10    # prior belief of how many predictors matter
)

burn_in <- 1000

ss_sum <- summary(ss_fit, burn = burn_in)

# matrix with columns:
# 1 post mean, 2 post sd,
# 3 mean|nonzero, 4 sd|nonzero,
# 5 Pr(nonzero)
coef_table <- ss_sum$coefficients

inc_prob <- coef_table[, 5]
inc_prob <- inc_prob[names(inc_prob) != "(Intercept)"]

inc_prob_sorted <- sort(inc_prob, decreasing = TRUE)
selected_vars <- names(inc_prob)[inc_prob > 0.5] # keep any nutrient whose coefficient is nonzero in more than half the posterior samples.
selected_vars
```

## Bayesian Linear Regression: Theory

$$Y = X\beta + \varepsilon,\quad \varepsilon ∼ \mathcal{N}_n(0,\, \sigma^2I)$$

$$\beta\, | \,\sigma^2 ∼ \mathcal{N}_p(\xi,\, \sigma^2\Omega),\quad \sigma^2 ∼ \operatorname{Inverse-Gamma}(\alpha,\, \beta)$$

$$\xi = 0, \quad \Omega = 10^3I_p,\quad \alpha = 0.01, \quad \beta = 0.01$$

Choose regressors, for which 95\% credible interval of $\beta$ does not include $0$.

## Bayesian Linear Regression: Full Model

```{r reg-full, echo=FALSE, results='asis'}
# Model 1: Full model with all variables as regressors
n_full <- nrow(X_scaled)
p_full <- ncol(X_scaled)

xi_full <- rep(0, p_full)
Omega_full <- 10^3 * diag(p_full)
alpha_full <- 0.01
b_full <- 0.01  # using b instead of beta for rate parameter

Omega_inverse_full <- solve(Omega_full)
Q_beta_full <- t(as.matrix(X_scaled)) %*% X_scaled + Omega_inverse_full
Q_beta_inverse_full <- solve(Q_beta_full)
l_beta_full <- t(as.matrix(X_scaled)) %*% y + Omega_inverse_full %*% xi_full

# Sampling posterior
samples_full <- 10^4
sigma_2_samples_full <- rinvgamma(
  samples_full,
  alpha_full + n_full / 2,
  b_full + t(y) %*% y / 2 +
    t(xi_full) %*% Omega_inverse_full %*% xi_full / 2 -
    t(l_beta_full) %*% Q_beta_inverse_full %*% l_beta_full / 2
)

beta_samples_full <- matrix(NA, nrow = samples_full, ncol = p_full)
for (s in 1:samples_full) {
  beta_samples_full[s, ] <- mvrnorm(
    1,
    Q_beta_inverse_full %*% l_beta_full,
    Sigma = sigma_2_samples_full[s] * Q_beta_inverse_full
  )
}

#hist(sigma_2_samples_full, xlab = expression(sigma^2))

# Credible intervals of betas
beta_summary_full <- data.frame(
  term = c("intercept", colnames(X[, -1])),
  mean = colMeans(beta_samples_full),
  low = apply(beta_samples_full, 2, quantile, 0.025),
  high = apply(beta_samples_full, 2, quantile, 0.975)
)
#beta_summary_full

selected_betas_full <- beta_summary_full[
  beta_summary_full[, "low"] > 0 | beta_summary_full[, "high"] < 0,
]

knitr::kable(selected_betas_full %>% 
               mutate(term = gsub("_", " ", term)) %>% 
               arrange(desc(mean)),
             col.names = c("Regressor", "Mean β", "2.5% quantile", "97.5% quantile"))
```


## Bayesian Linear Regression: Lasso with Fat

```{r reg-lassofat}
# Model 2: Bayesian Lasso Model with Fat included initially
X_scaled_BL_F <- X_scaled[, selected_nutrients, drop = FALSE]

n_BL_F <- nrow(X_scaled_BL_F)
p_BL_F <- ncol(X_scaled_BL_F)

# Prior settings
xi_BL_F <- rep(0, p_BL_F)
Omega_BL_F <- 10^3 * diag(p_BL_F)
alpha_BL_F <- 0.01
b_BL_F <- 0.01  # rate parameter

Omega_inverse_BL_F <- solve(Omega_BL_F)

Q_beta_BL_F <- t(as.matrix(X_scaled_BL_F)) %*% X_scaled_BL_F + Omega_inverse_BL_F
Q_beta_inverse_BL_F <- solve(Q_beta_BL_F)

l_beta_BL_F <- t(as.matrix(X_scaled_BL_F)) %*% y + Omega_inverse_BL_F %*% xi_BL_F

# Posterior sampling
samples_BL_F <- 10^4

sigma_2_samples_BL_F <- rinvgamma(
  samples_BL_F,
  alpha_BL_F + n_BL_F / 2,
  b_BL_F + t(y) %*% y / 2 +
    t(xi_BL_F) %*% Omega_inverse_BL_F %*% xi_BL_F / 2 -
    t(l_beta_BL_F) %*% Q_beta_inverse_BL_F %*% l_beta_BL_F / 2
)

beta_samples_BL_F <- matrix(NA, nrow = samples_BL_F, ncol = p_BL_F)

for (s in 1:samples_BL_F) {
  beta_samples_BL_F[s, ] <- mvrnorm(
    1,
    Q_beta_inverse_BL_F %*% l_beta_BL_F,
    Sigma = sigma_2_samples_BL_F[s] * Q_beta_inverse_BL_F
  )
}

#hist(sigma_2_samples_BL_F, xlab = expression(sigma^2))

# Credible intervals
beta_summary_BL_F <- data.frame(
  term = colnames(X_scaled_BL_F),
  mean = colMeans(beta_samples_BL_F),
  low = apply(beta_samples_BL_F, 2, quantile, 0.025),
  high = apply(beta_samples_BL_F, 2, quantile, 0.975)
)

#beta_summary_BL_F

selected_betas_BL_F <- beta_summary_BL_F[
  beta_summary_BL_F$low > 0 | beta_summary_BL_F$high < 0,
]


knitr::kable(selected_betas_BL_F %>% 
               mutate(term = gsub("_", " ", term)) %>% 
               arrange(desc(mean)),
             col.names = c("Regressor", "Mean β", "2.5% quantile", "97.5% quantile"))
```

## Bayesian Linear Regression: Lasso without Fat

```{r reg-lassonofat}
# Model 3: Bayesian Lasso Model without Fat included initially
X_scaled_BL <- X_scaled[, selected_nutrients_without_fat, drop = FALSE]

n_BL <- nrow(X_scaled_BL)
p_BL <- ncol(X_scaled_BL)

xi_BL <- rep(0, p_BL)
Omega_BL <- 10^3 * diag(p_BL)
alpha_BL <- 0.01
b_BL <- 0.01  # rate parameter

Omega_inverse_BL <- solve(Omega_BL)

Q_beta_BL <- t(as.matrix(X_scaled_BL)) %*% X_scaled_BL + Omega_inverse_BL
Q_beta_inverse_BL <- solve(Q_beta_BL)

l_beta_BL <- t(as.matrix(X_scaled_BL)) %*% y + Omega_inverse_BL %*% xi_BL

# Posterior sampling
samples_BL <- 10^4

sigma_2_samples_BL <- rinvgamma(
  samples_BL,
  alpha_BL + n_BL / 2,
  b_BL + t(y) %*% y / 2 +
    t(xi_BL) %*% Omega_inverse_BL %*% xi_BL / 2 -
    t(l_beta_BL) %*% Q_beta_inverse_BL %*% l_beta_BL / 2
)

beta_samples_BL <- matrix(NA, nrow = samples_BL, ncol = p_BL)

for (s in 1:samples_BL) {
  beta_samples_BL[s, ] <- mvrnorm(
    1,
    Q_beta_inverse_BL %*% l_beta_BL,
    Sigma = sigma_2_samples_BL[s] * Q_beta_inverse_BL
  )
}

# Plot sigma^2 samples
#hist(sigma_2_samples_BL, xlab = expression(sigma^2))

# Credible intervals
beta_summary_BL <- data.frame(
  term = colnames(X_scaled_BL),
  mean = colMeans(beta_samples_BL),
  low = apply(beta_samples_BL, 2, quantile, 0.025),
  high = apply(beta_samples_BL, 2, quantile, 0.975)
)

#beta_summary_BL

# Select coefficients with credible intervals not covering 0
selected_betas_BL <- beta_summary_BL[
  beta_summary_BL$low > 0 | beta_summary_BL$high < 0,
]


knitr::kable(selected_betas_BL %>% 
               mutate(term = gsub("_", " ", term)) %>% 
               arrange(desc(mean)),
             col.names = c("Regressor", "Mean β", "2.5% quantile", "97.5% quantile"))
```

## Bayesian Linear Regression: Spike-and-Slab

```{r reg-spikeslab}
# Model 4: Spike and Slab Prior
X_scaled_SS <- X_scaled[, selected_vars, drop = FALSE]
# If spike & slab chose nothing, stop early
if (length(selected_vars) == 0) {
  stop("Spike&Slab selected no variables (inc_prob > 0.5). Try lowering threshold.")
}

n_SS <- nrow(X_scaled_SS)
p_SS <- ncol(X_scaled_SS)

# Prior hyperparameters (same weakly-informative N-Inv-Gamma setup)
xi_SS <- rep(0, p_SS)
Omega_SS <- 10^3 * diag(p_SS)
alpha_SS <- 0.01
b_SS <- 0.01

Omega_inverse_SS <- solve(Omega_SS)

# Posterior precision and mean terms
Q_beta_SS <- t(as.matrix(X_scaled_SS)) %*% X_scaled_SS + Omega_inverse_SS
Q_beta_inverse_SS <- solve(Q_beta_SS)

l_beta_SS <- t(as.matrix(X_scaled_SS)) %*% y + Omega_inverse_SS %*% xi_SS

# Posterior sampling
samples_SS <- 10^4

sigma_2_samples_SS <- rinvgamma(
  samples_SS,
  alpha_SS + n_SS / 2,
  b_SS + t(y) %*% y / 2 +
    t(xi_SS) %*% Omega_inverse_SS %*% xi_SS / 2 -
    t(l_beta_SS) %*% Q_beta_inverse_SS %*% l_beta_SS / 2
)

beta_samples_SS <- matrix(NA, nrow = samples_SS, ncol = p_SS)

for (s in 1:samples_SS) {
  beta_samples_SS[s, ] <- mvrnorm(
    1,
    Q_beta_inverse_SS %*% l_beta_SS,
    Sigma = sigma_2_samples_SS[s] * Q_beta_inverse_SS
  )
}

# Plot sigma^2 posterior samples
#hist(sigma_2_samples_SS, xlab = expression(sigma^2),
#     main = "Posterior draws of sigma^2 (Spike&Slab Model)")

# Credible intervals for betas
beta_summary_SS <- data.frame(
  term = colnames(X_scaled_SS),
  mean = colMeans(beta_samples_SS),
  low = apply(beta_samples_SS, 2, quantile, 0.025),
  high = apply(beta_samples_SS, 2, quantile, 0.975)
)

#beta_summary_SS

# Select coefficients whose 95% CI excludes 0
selected_betas_SS <- beta_summary_SS[
  beta_summary_SS$low > 0 | beta_summary_SS$high < 0,
]


knitr::kable(selected_betas_SS %>% 
               mutate(term = gsub("_", " ", term)) %>% 
               arrange(desc(mean)),
             col.names = c("Regressor", "Mean β", "2.5% quantile", "97.5% quantile"))
```



<!-- Model Comparison -->

```{r ttsplit, include=FALSE}
set.seed(123)

n <- nrow(df)
train_idx <- sample(seq_len(n), size = floor(0.8 * n))
test_idx  <- setdiff(seq_len(n), train_idx)

X_train <- X[train_idx, , drop = FALSE]
X_test  <- X[test_idx,  , drop = FALSE]
y_train <- y[train_idx]
y_test  <- y[test_idx]

# ---- scale using TRAIN stats only
train_means <- apply(X_train, 2, mean)
train_sds   <- apply(X_train, 2, sd)

scale_with_train <- function(Xmat, mu, sdv) {
  sweep(sweep(as.matrix(Xmat), 2, mu, "-"), 2, sdv, "/")
}

X_train_scaled <- scale_with_train(X_train, train_means, train_sds)
X_test_scaled  <- scale_with_train(X_test,  train_means, train_sds)
```

```{r ttmodels, include=FALSE}
fit_conjugate_blr <- function(Xtr_sc, ytr, Xte_sc, yte,
                                 samples = 1e4,
                                 alpha0 = 0.01, b0 = 0.01,
                                 Omega_scale = 1e3) {
  
  n_tr <- nrow(Xtr_sc)
  p_tr <- ncol(Xtr_sc)
  
  xi <- rep(0, p_tr)
  Omega <- Omega_scale * diag(p_tr)
  Omega_inv <- solve(Omega)
  
  Q_beta <- t(Xtr_sc) %*% Xtr_sc + Omega_inv
  Q_beta_inv <- solve(Q_beta)
  l_beta <- t(Xtr_sc) %*% ytr + Omega_inv %*% xi
  
  # posterior draws
  sigma2_draws <- rinvgamma(
    samples,
    alpha0 + n_tr / 2,
    b0 + t(ytr) %*% ytr / 2 +
      t(xi) %*% Omega_inv %*% xi / 2 -
      t(l_beta) %*% Q_beta_inv %*% l_beta / 2
  )
  
  beta_draws <- matrix(NA, nrow = samples, ncol = p_tr)
  beta_mean_post <- as.vector(Q_beta_inv %*% l_beta)
  
  for (s in 1:samples) {
    beta_draws[s, ] <- mvrnorm(
      1, mu = beta_mean_post,
      Sigma = sigma2_draws[s] * Q_beta_inv
    )
  }
  
  beta_post_mean <- colMeans(beta_draws)
  
  # posterior mean predictions on test
  yhat_test <- as.vector(Xte_sc %*% beta_post_mean)
  
  # Test MSE
  mse <- mean((yte - yhat_test)^2)
  
  # test R^2
  sse <- sum((yte - yhat_test)^2)
  sst <- sum((yte - mean(yte))^2)
  r2  <- 1 - sse / sst
  
  list(r2 = r2, mse = mse, beta_post_mean = beta_post_mean)
}

# ===============================================
# Model 1: Full model (all predictors)
# ===============================================
m1 <- fit_conjugate_blr(X_train_scaled, y_train,
                           X_test_scaled,  y_test)

# ===============================================
# Model 2: Bayesian Lasso selection (with Fat)
#   selection on TRAIN only
# ===============================================
set.seed(123)
bl_fit_tr <- blasso(
  X = X_train_scaled,
  y = y_train,
  T = 10000,
  thin = 5,
  verb = 0
)

beta_ci_tr <- t(apply(bl_fit_tr$beta, 2, quantile, probs = c(0.025, 0.975)))
colnames(beta_ci_tr) <- c("low", "high")

selected_lasso_ci_tr <- rownames(beta_ci_tr)[
  beta_ci_tr[, "low"] > 0 | beta_ci_tr[, "high"] < 0
]

idx_sel_tr <- as.integer(sub("b\\.", "", selected_lasso_ci_tr))
selected_nutrients_tr <- colnames(X_train_scaled)[idx_sel_tr]

# subset train/test using the SAME columns
Xtr_BL_F <- X_train_scaled[, selected_nutrients_tr, drop = FALSE]
Xte_BL_F <- X_test_scaled[,  selected_nutrients_tr, drop = FALSE]

m2 <- fit_conjugate_blr(Xtr_BL_F, y_train,
                           Xte_BL_F, y_test)

# ===============================================
# Model 3: Bayesian Lasso selection (without Fat)
#   selection on TRAIN only
# ===============================================
# remove Fat BEFORE scaling to keep correct alignment
X_train_wofat <- X_train %>% dplyr::select(-Fat)
X_test_wofat  <- X_test  %>% dplyr::select(-Fat)

mu_wofat <- apply(X_train_wofat, 2, mean)
sd_wofat <- apply(X_train_wofat, 2, sd)

Xtr_wofat_sc <- scale_with_train(X_train_wofat, mu_wofat, sd_wofat)
Xte_wofat_sc <- scale_with_train(X_test_wofat,  mu_wofat, sd_wofat)

set.seed(123)
bl_fit_wofat_tr <- blasso(
  X = Xtr_wofat_sc,
  y = y_train,
  T = 10000,
  thin = 5,
  verb = 0
)

beta_ci_wofat_tr <- t(apply(bl_fit_wofat_tr$beta, 2, quantile, probs = c(0.025, 0.975)))
colnames(beta_ci_wofat_tr) <- c("low", "high")

selected_lasso_ci_wofat_tr <- rownames(beta_ci_wofat_tr)[
  beta_ci_wofat_tr[, "low"] > 0 | beta_ci_wofat_tr[, "high"] < 0
]

idx_sel_wofat_tr <- as.integer(sub("b\\.", "", selected_lasso_ci_wofat_tr))
selected_nutrients_wofat_tr <- colnames(Xtr_wofat_sc)[idx_sel_wofat_tr]

Xtr_BL <- Xtr_wofat_sc[, selected_nutrients_wofat_tr, drop = FALSE]
Xte_BL <- Xte_wofat_sc[, selected_nutrients_wofat_tr, drop = FALSE]

m3 <- fit_conjugate_blr(Xtr_BL, y_train,
                           Xte_BL, y_test)

# ===============================================
# Model 4: Spike & Slab selection
#   selection on TRAIN only
# ===============================================
set.seed(123)
df_model_tr <- data.frame(
  y = as.numeric(y_train),
  as.data.frame(X_train_scaled)
)

ss_fit_tr <- lm.spike(
  y ~ .,
  data  = df_model_tr,
  niter = 6000,
  expected.model.size = 10
)

burn_in <- 1000
ss_sum_tr <- summary(ss_fit_tr, burn = burn_in)
coef_table_tr <- ss_sum_tr$coefficients

inc_prob_tr <- coef_table_tr[, 5]
inc_prob_tr <- inc_prob_tr[names(inc_prob_tr) != "(Intercept)"]

selected_vars_tr <- names(inc_prob_tr)[inc_prob_tr > 0.5]

if (length(selected_vars_tr) == 0) {
  stop("Spike&Slab selected no variables on TRAIN (inc_prob > 0.5). Lower threshold.")
}

Xtr_SS <- X_train_scaled[, selected_vars_tr, drop = FALSE]
Xte_SS <- X_test_scaled[,  selected_vars_tr, drop = FALSE]

m4 <- fit_conjugate_blr(Xtr_SS, y_train,
                           Xte_SS, y_test)



# ===============================================
# Model 5: Only Fat + Carbohydrates + Protein
# ===============================================

vars_m5 <- c("Fat", "Carbohydrates", "Protein")

# make sure they exist
stopifnot(all(vars_m5 %in% colnames(X_train)))

# subset original (unscaled) train/test
X_train_m5 <- X_train[, vars_m5, drop = FALSE]
X_test_m5  <- X_test[,  vars_m5, drop = FALSE]

# scale using TRAIN stats of these 3 variables
mu_m5 <- apply(X_train_m5, 2, mean)
sd_m5 <- apply(X_train_m5, 2, sd)

Xtr_m5_sc <- scale_with_train(X_train_m5, mu_m5, sd_m5)
Xte_m5_sc <- scale_with_train(X_test_m5,  mu_m5, sd_m5)

m5 <- fit_conjugate_blr(Xtr_m5_sc, y_train,
                           Xte_m5_sc, y_test)
```

## Model Comparison

```{r models, echo=FALSE, results='asis'}
r2_table <- tibble(
  Model = c("1: Full",
            "2: BLasso (with Fat)",
            "3: BLasso (no Fat)",
            "4: Spike&Slab",
            "5: Fat+Carbs+Protein only"),
  Test_R2 = c(m1$r2, m2$r2, m3$r2, m4$r2, m5$r2),
  Test_MSE = c(m1$mse, m2$mse, m3$mse, m4$mse, m5$mse),
  Num_Predictors = c(
    ncol(X_train_scaled),
    ncol(Xtr_BL_F),
    ncol(Xtr_BL),
    ncol(Xtr_SS),
    ncol(Xtr_m5_sc)
  )
)

knitr::kable(r2_table %>% 
               mutate(Test_R2 = round(Test_R2, 5),
                      Test_MSE = round(Test_MSE, 0)),
             col.names = c("Model", "R²", "MSE", "N Regressors"))
```

Train-test split: 80\% - 20\%

## Conclusions

-   No idea

# Thank you!
